{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a5b0836-0180-4d8a-a834-4596b826d2fe",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# df_ride_info = spark.read \\\n",
    "#   .parquet(\"s3://dsoaws/nyc-taxi-orig-cleaned-split-parquet-per-year-multiple-files/ride-info/\") \n",
    "\n",
    "# df_ride_fare = spark.read \\\n",
    "#   .parquet(\"s3://dsoaws/nyc-taxi-orig-cleaned-split-parquet-per-year-multiple-files/ride-fare/\")\n",
    "\n",
    "# df_model_training = df_ride_info.join(df_ride_fare, on=\"ride_id\") \\\n",
    "#                                 .drop(df_ride_fare.ride_id) \\\n",
    "#                                 .drop(df_ride_fare.year)\n",
    "\n",
    "# df_model_training = df_model_training \\\n",
    "#   .drop(\"ride_id\") \\\n",
    "#   .drop(\"pickup_at\") \\\n",
    "#   .drop(\"dropoff_at\") \\\n",
    "#   .drop(\"store_and_fwd_flag\")\n",
    "\n",
    "# df_train = df_model_training # for now, we keep them the same as we want all 1 billion rows to be used for training\n",
    "# df_test = df_model_training # for now, we keep them the same as we are not actually comparing RMSE between the models\n",
    "\n",
    "# df_train, df_test = df_model_training.randomSplit([0.70, 0.30], seed = 0)\n",
    "\n",
    "# df_train = spark.read.option(\"recursiveFileLookup\", \"true\").parquet('s3://dsoaws/gsml-nyc-taxi-full-etl-ml-test-4-custompyspark-export-s3-via-notebook/export-flow-2023-03-02-03-32-10-53926e35/output/training/')\n",
    "\n",
    "# df_test = spark.read.option(\"recursiveFileLookup\", \"true\").parquet('s3://dsoaws/gsml-nyc-taxi-full-etl-ml-test-4-custompyspark-export-s3-via-notebook/export-flow-2023-03-02-03-32-10-53926e35/output/validation/')\n",
    "\n",
    "# print(\"There are %d training and %d test examples.\" % (df_train.count(), df_test.count()))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f86c671c-87ea-44a1-aded-ff80431427fe",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_train = spark.read.option(\"recursiveFileLookup\", \"true\") \\\n",
    "  .parquet('s3://dsoaws/nyc-taxi-orig-cleaned-dropped-parquet-all-years-multiple-files-100GB/')\n",
    "\n",
    "df_train.cache()\n",
    "\n",
    "df_train.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "666d848c-8e84-4268-96a2-c0b050a4655a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "",
       "errorTraceType": null,
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# adjust for too much data above ^^\n",
    "# df_train, _ = df_train.randomSplit([0.70, 0.30], seed = 0)\n",
    "\n",
    "# _, df_test = df_test.randomSplit([0.70, 0.30], seed = 0)\n",
    "\n",
    "# print(\"There are %d training and %d test examples.\" % (df_train.count(), df_test.count()))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "95ba0e74-9804-4194-8532-3fff4037ab9e",
     "showTitle": false,
     "title": null
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "",
       "errorTraceType": null,
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler, VectorIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "import xgboost\n",
    "from xgboost.spark import SparkXGBRegressor\n",
    "\n",
    "featuresCols = df_train.columns\n",
    "featuresCols.remove('total_amount')\n",
    "\n",
    "vectorAssembler = VectorAssembler(inputCols=featuresCols,\n",
    "                                  outputCol=\"rawFeatures\",\n",
    "                                  handleInvalid=\"skip\")\n",
    "\n",
    "vectorIndexer = VectorIndexer(inputCol=\"rawFeatures\", \n",
    "                              outputCol=\"features\", \n",
    "                              maxCategories=100, \n",
    "                              handleInvalid=\"skip\")\n",
    "\n",
    "xgb_regressor = SparkXGBRegressor(num_workers=480,\n",
    "                                  label_col=\"total_amount\", \n",
    "                                  missing=0.0,\n",
    "                                  eta=0.2,\n",
    "                                  gamma=4,\n",
    "                                  max_depth=5,\n",
    "                                  min_child_weight=6,\n",
    "                                  num_round=50,\n",
    "                                  objective='reg:squarederror',\n",
    "                                  subsample=0.7)\n",
    "\n",
    "pipeline = Pipeline(stages=[vectorAssembler, vectorIndexer, xgb_regressor])      \n",
    "\n",
    "pipelineModel = pipeline.fit(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b87b2ed7-4f36-482e-b8bd-3067c325ef94",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "",
       "errorTraceType": null,
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "featuresCols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "31efa9b1-7bdd-4fc8-abc8-85781868b8ae",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff272629-276a-4ad3-9935-45055d62f4a6",
     "showTitle": false,
     "title": null
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "",
       "errorTraceType": null,
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# predictions = pipelineModel.transform(df_test)\n",
    "\n",
    "# display(predictions.select(\"total_amount\", \"prediction\", *featuresCols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6e77a7fe-6eea-47c2-9ea7-1d17030927f9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Evaluate root mean squared error (`rmse`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5dd331d1-c840-44a1-9acb-38c4b2819813",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "",
       "errorTraceType": null,
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\",\n",
    "                                labelCol=xgb_regressor.getLabelCol(),\n",
    "                                predictionCol=xgb_regressor.getPredictionCol())\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "\n",
    "print(\"RMSE on our test set: %g\" % rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e7120ed-feb7-4843-8294-c99185f1609f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Save and reload the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "92eaa561-b8d6-4632-a91c-c8349823af0f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "",
       "errorTraceType": null,
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sh\n",
    "rm -rf /dbfs/tmp/xgboost/pipeline_001\n",
    "rm -rf /dbfs/tmp/xgboost/pipelineModel_001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0b63175b-2907-4899-8c8f-94de5c4d83f1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "",
       "errorTraceType": null,
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Save the pipeline that created the model\n",
    "pipeline.save('/tmp/xgboost/pipeline_001')\n",
    "\n",
    "# Save the model itself\n",
    "pipelineModel.save('/tmp/xgboost/pipelineModel_001')\n",
    "\n",
    "# Load the pipeline\n",
    "loaded_pipeline = Pipeline.load('/tmp/xgboost/pipeline_001')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d0c4529-7b6b-4ffa-853d-4fa263591fa4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Predict from loaded pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee57e9bd-0e0b-4c56-8994-dced4d9ae515",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "",
       "errorTraceType": null,
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Load and use the model\n",
    "# from pyspark.ml import PipelineModel\n",
    "\n",
    "# loaded_pipelineModel = PipelineModel.load('/tmp/xgboost/pipelineModel_001')\n",
    "\n",
    "# # To represent new data, use the first 3 rows of the test dataset\n",
    "# new_data = df_test.limit(3)\n",
    "\n",
    "# # Make predictions with the loaded model\n",
    "# new_preds = loaded_pipelineModel.transform(new_data)\n",
    "# display(new_preds.select(\"total_amount\", \"prediction\", *featuresCols))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [
    {
     "elements": [],
     "globalVars": {},
     "guid": "ffd9451a-f0c1-40c2-a986-13f563e15e8b",
     "layoutOption": {
      "grid": true,
      "stack": true
     },
     "nuid": "4d2f9134-6ec5-41a2-9f28-fd70226726cd",
     "origId": 3736256471047291,
     "title": "Untitled",
     "version": "DashboardViewV1",
     "width": 1024
    }
   ],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 3736256471047287,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "nyctaxi-pyspark-xgboost",
   "notebookOrigID": 3736256471047250,
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "",
   "name": ""
  },
  "language_info": {
   "name": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
