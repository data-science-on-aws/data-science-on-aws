{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mtensorflow 2.0.0 requires opt-einsum>=2.3.2, which is not installed.\u001b[0m\n",
      "\u001b[31mtensorflow 2.0.0 has requirement gast==0.2.2, but you'll have gast 0.3.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mawscli 1.18.11 has requirement botocore==1.15.11, but you'll have botocore 1.14.17 which is incompatible.\u001b[0m\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "\n",
    "sess   = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "sm = boto3.Session().client(service_name='sagemaker', region_name=region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix', 'S3Uri': 's3://sagemaker-us-east-1-835319576252/feature-store/amazon-reviews/csv/balanced-tfidf-without-header/train/data.csv', 'S3DataDistributionType': 'FullyReplicated'}}, 'ContentType': 'text/csv'}\n",
      "{'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix', 'S3Uri': 's3://sagemaker-us-east-1-835319576252/feature-store/amazon-reviews/csv/balanced-tfidf-without-header/validation/data.csv', 'S3DataDistributionType': 'FullyReplicated'}}, 'ContentType': 'text/csv'}\n",
      "{'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix', 'S3Uri': 's3://sagemaker-us-east-1-835319576252/feature-store/amazon-reviews/csv/balanced-tfidf-without-header/test/data.csv', 'S3DataDistributionType': 'FullyReplicated'}}, 'ContentType': 'text/csv'}\n"
     ]
    }
   ],
   "source": [
    "prefix_train = 'feature-store/amazon-reviews/csv/balanced-tfidf-without-header/train'\n",
    "prefix_validation = 'feature-store/amazon-reviews/csv/balanced-tfidf-without-header/validation'\n",
    "prefix_test = 'feature-store/amazon-reviews/csv/balanced-tfidf-without-header/test'\n",
    "\n",
    "balanced_tfidf_without_header_train_s3_uri = 's3://{}/{}/data.csv'.format(bucket, prefix_train)\n",
    "balanced_tfidf_without_header_validation_s3_uri = 's3://{}/{}/data.csv'.format(bucket, prefix_validation)\n",
    "balanced_tfidf_without_header_test_s3_uri = 's3://{}/{}/data.csv'.format(bucket, prefix_test)\n",
    "\n",
    "s3_input_train_data = sagemaker.s3_input(s3_data=balanced_tfidf_without_header_train_s3_uri, content_type='text/csv')\n",
    "s3_input_validation_data = sagemaker.s3_input(s3_data=balanced_tfidf_without_header_validation_s3_uri, content_type='text/csv')\n",
    "s3_input_test_data = sagemaker.s3_input(s3_data=balanced_tfidf_without_header_test_s3_uri, content_type='text/csv')\n",
    "\n",
    "print(s3_input_train_data.config)\n",
    "print(s3_input_validation_data.config)\n",
    "print(s3_input_test_data.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.amazon.amazon_estimator import get_image_uri \n",
    "\n",
    "# get the URI for new container\n",
    "builtin_container_uri = get_image_uri(region_name=region,                                \n",
    "                                      repo_name='xgboost', \n",
    "                                      repo_version='0.90-2')\n",
    "\n",
    "model_output_path = 's3://{}/models/built-in/training-runs'.format(bucket)\n",
    "\n",
    "xgb_estimator = sagemaker.estimator.Estimator(image_name=builtin_container_uri, \n",
    "                                              role=role, \n",
    "                                              hyperparameters={'objective':'binary:logistic',\n",
    "                                                               'num_round': 1,\n",
    "                                                               'max_depth': 5},\n",
    "                                              train_instance_count=1, \n",
    "                                              train_instance_type='ml.m4.xlarge', \n",
    "                                              output_path=model_output_path, \n",
    "                                              sagemaker_session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-04 05:19:07 Starting - Starting the training job...\n",
      "2020-03-04 05:19:09 Starting - Launching requested ML instances......\n",
      "2020-03-04 05:20:16 Starting - Preparing the instances for training......\n",
      "2020-03-04 05:21:20 Downloading - Downloading input data...\n",
      "2020-03-04 05:22:03 Training - Downloading the training image...\n",
      "2020-03-04 05:22:35 Uploading - Uploading generated training model\n",
      "2020-03-04 05:22:35 Completed - Training job completed\n",
      "\u001b[34mINFO:sagemaker-containers:Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Failed to parse hyperparameter objective value binary:logistic to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34mINFO:sagemaker_xgboost_container.training:Running XGBoost Sagemaker in algorithm mode\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[05:22:26] 32054x300 matrix with 9616200 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[05:22:26] 1781x300 matrix with 534300 entries loaded from /opt/ml/input/data/validation?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34mINFO:root:Single node training.\u001b[0m\n",
      "\u001b[34mINFO:root:Train matrix has 32054 rows\u001b[0m\n",
      "\u001b[34mINFO:root:Validation matrix has 1781 rows\u001b[0m\n",
      "\u001b[34m[0]#011train-error:0.239284#011validation-error:0.35991\u001b[0m\n",
      "Training seconds: 75\n",
      "Billable seconds: 75\n"
     ]
    }
   ],
   "source": [
    "xgb_estimator.fit({'train': s3_input_train_data,\n",
    "                   'validation': s3_input_validation_data\n",
    "                  }\n",
    "                  #, wait=False\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_job_name:  sagemaker-xgboost-2020-03-04-05-19-07-509\n"
     ]
    }
   ],
   "source": [
    "training_job_name = xgb_estimator.latest_training_job.name\n",
    "print('training_job_name:  {}'.format(training_job_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:  This is broken\n",
    "#from sagemaker.xgboost import XGBoost\n",
    "\n",
    "#xgb_estimator = XGBoost.attach(training_job_name=training_job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 2.7 KiB/2.7 KiB (31.5 KiB/s) with 1 file(s) remaining\r",
      "download: s3://sagemaker-us-east-1-835319576252/models/built-in/training-runs/sagemaker-xgboost-2020-03-04-05-19-07-509/output/model.tar.gz to models/built-in/model.tar.gz\r\n"
     ]
    }
   ],
   "source": [
    "# download the model artifact from AWS S3\n",
    "!aws s3 cp $model_output_path/$training_job_name/output/model.tar.gz ./models/built-in/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import pickle as pkl\n",
    "\n",
    "# TODO:  extract to ./model/built-in/\n",
    "\n",
    "#opens the downloaded model artifcat and loads it as 'model' variable\n",
    "tar = tarfile.open('./models/built-in/model.tar.gz')\n",
    "tar.extractall(path='./models/built-in/')\n",
    "tar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 20\r\n",
      "drwxrwxr-x 2 ec2-user ec2-user 4096 Mar  4 05:22 .\r\n",
      "drwxrwxr-x 4 ec2-user ec2-user 4096 Mar  4 04:55 ..\r\n",
      "-rw-rw-r-- 1 ec2-user ec2-user 2725 Mar  4 05:22 model.tar.gz\r\n",
      "-rw-r--r-- 1 ec2-user ec2-user 6254 Mar  4 05:22 xgboost-model\r\n"
     ]
    }
   ],
   "source": [
    "!ls -al ./models/built-in/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_restored = pkl.load(open('./models/built-in/xgboost-model', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO:  Calculate Validation and Test Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# $S3_BUCKET/feature-store/amazon-reviews/balanced-tfidf-without-header/data.csv\n",
    "\n",
    "prefix_test = 'feature-store/amazon-reviews/csv/balanced-tfidf-without-header/test'\n",
    "\n",
    "balanced_tfidf_without_header_test_path = './{}/data.csv'.format(prefix_test)\n",
    "\n",
    "import os\n",
    "os.makedirs(prefix_test, exist_ok=True)\n",
    "\n",
    "balanced_tfidf_without_header_test_s3_uri = 's3://{}/{}/data.csv'.format(bucket, prefix_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-us-east-1-835319576252/feature-store/amazon-reviews/csv/balanced-tfidf-without-header/test/data.csv to feature-store/amazon-reviews/csv/balanced-tfidf-without-header/test/data.csv\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp $balanced_tfidf_without_header_test_s3_uri $balanced_tfidf_without_header_test_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data\n",
    "_Note:  `header=None`_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path, sep, header):\n",
    "    data = pd.read_csv(path, sep=sep, header=header)\n",
    "\n",
    "    labels = data.iloc[:,0]\n",
    "    features = data.drop(data.columns[0], axis=1)\n",
    "    \n",
    "    if header==None:\n",
    "        # Adjust the column names after dropped the 0th column above\n",
    "        # New column names are 0 (inclusive) to len(features.columns) (exclusive)\n",
    "        new_column_names = list(range(0, len(features.columns)))\n",
    "        features.columns = new_column_names\n",
    "\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = load_dataset(path=balanced_tfidf_without_header_test_path, sep=',', header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.634733</td>\n",
       "      <td>-0.247392</td>\n",
       "      <td>0.069444</td>\n",
       "      <td>-0.523243</td>\n",
       "      <td>-0.004713</td>\n",
       "      <td>-0.448801</td>\n",
       "      <td>-0.204092</td>\n",
       "      <td>-0.238300</td>\n",
       "      <td>-0.261760</td>\n",
       "      <td>-0.219047</td>\n",
       "      <td>...</td>\n",
       "      <td>0.164698</td>\n",
       "      <td>-0.557045</td>\n",
       "      <td>-0.381416</td>\n",
       "      <td>-0.103129</td>\n",
       "      <td>-0.209871</td>\n",
       "      <td>-0.556612</td>\n",
       "      <td>1.304991</td>\n",
       "      <td>0.499820</td>\n",
       "      <td>1.384731</td>\n",
       "      <td>-0.083465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.258064</td>\n",
       "      <td>-1.061612</td>\n",
       "      <td>-0.027788</td>\n",
       "      <td>-0.435960</td>\n",
       "      <td>0.519479</td>\n",
       "      <td>-0.291335</td>\n",
       "      <td>0.263390</td>\n",
       "      <td>-0.780300</td>\n",
       "      <td>-0.411519</td>\n",
       "      <td>-0.517505</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.080147</td>\n",
       "      <td>0.484613</td>\n",
       "      <td>0.113549</td>\n",
       "      <td>-0.315451</td>\n",
       "      <td>0.965301</td>\n",
       "      <td>-2.017522</td>\n",
       "      <td>0.042569</td>\n",
       "      <td>-0.315694</td>\n",
       "      <td>-1.637476</td>\n",
       "      <td>1.099162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.123441</td>\n",
       "      <td>-0.381155</td>\n",
       "      <td>0.220870</td>\n",
       "      <td>-0.306529</td>\n",
       "      <td>0.295466</td>\n",
       "      <td>0.015603</td>\n",
       "      <td>0.808974</td>\n",
       "      <td>-0.886816</td>\n",
       "      <td>-0.537187</td>\n",
       "      <td>-1.609552</td>\n",
       "      <td>...</td>\n",
       "      <td>0.907523</td>\n",
       "      <td>-1.370449</td>\n",
       "      <td>-0.497941</td>\n",
       "      <td>-0.000245</td>\n",
       "      <td>-0.229369</td>\n",
       "      <td>-0.549921</td>\n",
       "      <td>-0.901384</td>\n",
       "      <td>0.611026</td>\n",
       "      <td>0.231871</td>\n",
       "      <td>-1.763118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.085429</td>\n",
       "      <td>-0.558576</td>\n",
       "      <td>-0.111424</td>\n",
       "      <td>-0.648954</td>\n",
       "      <td>-0.045818</td>\n",
       "      <td>-0.389012</td>\n",
       "      <td>-0.304378</td>\n",
       "      <td>-0.226467</td>\n",
       "      <td>0.129833</td>\n",
       "      <td>-0.374666</td>\n",
       "      <td>...</td>\n",
       "      <td>1.990565</td>\n",
       "      <td>0.674278</td>\n",
       "      <td>1.541115</td>\n",
       "      <td>-1.362709</td>\n",
       "      <td>-0.785404</td>\n",
       "      <td>2.047984</td>\n",
       "      <td>0.874032</td>\n",
       "      <td>-0.547825</td>\n",
       "      <td>-0.133409</td>\n",
       "      <td>0.407323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.943603</td>\n",
       "      <td>-0.748338</td>\n",
       "      <td>-0.302065</td>\n",
       "      <td>-0.454148</td>\n",
       "      <td>-0.777959</td>\n",
       "      <td>-1.025572</td>\n",
       "      <td>-0.138429</td>\n",
       "      <td>0.392192</td>\n",
       "      <td>-0.901120</td>\n",
       "      <td>0.385676</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.930250</td>\n",
       "      <td>1.317045</td>\n",
       "      <td>-1.353617</td>\n",
       "      <td>0.330193</td>\n",
       "      <td>-0.600254</td>\n",
       "      <td>0.714468</td>\n",
       "      <td>-1.320635</td>\n",
       "      <td>-2.121154</td>\n",
       "      <td>-0.086226</td>\n",
       "      <td>-0.318210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0 -0.634733 -0.247392  0.069444 -0.523243 -0.004713 -0.448801 -0.204092   \n",
       "1  1.258064 -1.061612 -0.027788 -0.435960  0.519479 -0.291335  0.263390   \n",
       "2 -0.123441 -0.381155  0.220870 -0.306529  0.295466  0.015603  0.808974   \n",
       "3 -0.085429 -0.558576 -0.111424 -0.648954 -0.045818 -0.389012 -0.304378   \n",
       "4  0.943603 -0.748338 -0.302065 -0.454148 -0.777959 -1.025572 -0.138429   \n",
       "\n",
       "        7         8         9    ...       290       291       292       293  \\\n",
       "0 -0.238300 -0.261760 -0.219047  ...  0.164698 -0.557045 -0.381416 -0.103129   \n",
       "1 -0.780300 -0.411519 -0.517505  ... -0.080147  0.484613  0.113549 -0.315451   \n",
       "2 -0.886816 -0.537187 -1.609552  ...  0.907523 -1.370449 -0.497941 -0.000245   \n",
       "3 -0.226467  0.129833 -0.374666  ...  1.990565  0.674278  1.541115 -1.362709   \n",
       "4  0.392192 -0.901120  0.385676  ... -0.930250  1.317045 -1.353617  0.330193   \n",
       "\n",
       "        294       295       296       297       298       299  \n",
       "0 -0.209871 -0.556612  1.304991  0.499820  1.384731 -0.083465  \n",
       "1  0.965301 -2.017522  0.042569 -0.315694 -1.637476  1.099162  \n",
       "2 -0.229369 -0.549921 -0.901384  0.611026  0.231871 -1.763118  \n",
       "3 -0.785404  2.047984  0.874032 -0.547825 -0.133409  0.407323  \n",
       "4 -0.600254  0.714468 -1.320635 -2.121154 -0.086226 -0.318210  \n",
       "\n",
       "[5 rows x 300 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import xgboost\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "xgboost.plot_importance(model_restored, \n",
    "                        importance_type='gain', \n",
    "                        max_num_features=30, \n",
    "                        height=0.8, \n",
    "                        ax=ax, \n",
    "                        show_values = True)\n",
    "plt.title('Feature Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, classification_report, confusion_matrix\n",
    "\n",
    "#auc = model_restored.score(X_test, y_test)\n",
    "#print('Test AUC ', auc)\n",
    "\n",
    "model_restored.feature_names = X_test.columns\n",
    "#preds_test = model_restored.predict(X_test)\n",
    "#print('Test Accuracy: ', accuracy_score(y_test, preds_test))\n",
    "#print('Test Precision: ', precision_score(y_test, preds_test, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preds_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-3c633057fc87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'preds_test' is not defined"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, preds_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Deploy Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/xgboost-in-amazon-sagemaker-28e5e354dbcd\n",
    "from sagemaker.predictor import csv_serializer\n",
    "\n",
    "## Deploy trained XGBoost model endpoint to perform predictions\n",
    "xgb_predictor = xgb_estimator.deploy(initial_instance_count = 1, instance_type = 'ml.m4.xlarge')\n",
    "\n",
    "xgb_predictor.content_type = 'text/csv'\n",
    "xgb_predictor.serializer = csv_serializer\n",
    "xgb_predictor.deserializer = None\n",
    "\n",
    "## ?? Function to chunk down test set into smaller increments\n",
    "\n",
    "# TODO:  1) update this to do TF/IDF\n",
    "#        2) use this in other versions of the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data, model, rows=500):\n",
    "    split_array = np.array_split(data, int(data.shape[0] / float(rows) + 1))\n",
    "    predictions = ''\n",
    "\n",
    "#        response = runtime_client.invoke_endpoint(EndpointName = endpoint_name,\n",
    "#                                         ContentType = 'text/csv',\n",
    "#                                         Body = single_test)\n",
    "        \n",
    "    for array in split_array:\n",
    "        predictions = ','.join([predictions, model.predict(array).decode('utf-8')])\n",
    "\n",
    "    return np.fromstring(predictions[1:], sep=',')\n",
    "\n",
    "## Generate predictions on the test set for the difference models\n",
    "\n",
    "predictions = predict(X_test.columns.values, xgb_predictor, rows=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/xgboost-in-amazon-sagemaker-28e5e354dbcd\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score\n",
    "\n",
    "def calc_specificity(y_true, y_pred, thresh):\n",
    "    # calculates specificity\n",
    "    return sum((y_pred < thresh) & (y_true == 0)) /sum(y_true ==0)\n",
    "\n",
    "thresh = 0.5\n",
    "y_pred = predictions\n",
    "y_pred_binary = np.where(predictions > thresh, 1, 0)\n",
    "y_true = test_data['OUTPUT_LABEL']\n",
    "\n",
    "c_mat = confusion_matrix(y_true, y_pred_binary) ## Predicted vs. actual outcome\n",
    "auc = round(roc_auc_score(y_true, y_pred),4)\n",
    "accuracy = round(accuracy_score(y_true,(y_pred > thresh) ) ,4)\n",
    "recall = round(recall_score(y_true, (y_pred > thresh)),4)\n",
    "precision = round(precision_score(y_true, (y_pred > thresh)),4)\n",
    "specificity = round(calc_specificity(y_true, y_pred, thresh),4)\n",
    "\n",
    "class_names = ['Not Readmitted', 'Readmitted'] ## Different class names\n",
    "\n",
    "def plot_conf_mat(cm, classes, title, cmap = plt.cm.Blues):                                 \n",
    "                                              \n",
    "    print(cm)\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "        horizontalalignment=\"center\",\n",
    "        color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.ylabel('True label')\n",
    "        plt.xlabel('Predicted label')\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "fig, ax = plt.subplots(figsize=(6,4))\n",
    "plot_conf_mat(c_mat, classes=class_names, \n",
    "                          title='Confusion matrix')\n",
    "plt.show()\n",
    "print(f'AUC is: {auc}')\n",
    "print(f'Accuracy is: {accuracy}')\n",
    "print(f'Recall is: {recall}')\n",
    "print(f'Precision is: {precision}')\n",
    "print(f'Specificity is: {specificity}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "auc = round(roc_auc_score(y_true, y_pred), 4)\n",
    "print('AUC is ' + repr(auc))\n",
    "\n",
    "fpr, tpr, _ = metrics.roc_curve(y_true, y_pred)\n",
    "\n",
    "plt.title('ROC Curve')\n",
    "plt.plot(fpr, tpr, 'b',\n",
    "label='AUC = %0.2f'% auc)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "plt.xlim([-0.1,1.1])\n",
    "plt.ylim([-0.1,1.1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:  1) update this to do TF/IDF\n",
    "#        2) use this in other versions of the model\n",
    "# Derived from the following:\n",
    "#   https://aim357.readthedocs.io/en/latest/GluePySparkMLFeatureEngineering/GluePySparkMLFeatureEngineering.html#deepar-deep-dive\n",
    "\n",
    "class XGBoostPredictor(sagemaker.predictor.RealTimePredictor):\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, content_type=sagemaker.content_types.CONTENT_TYPE_JSON, **kwargs)\n",
    "\n",
    "    def predict(self, ts, cat=None, dynamic_feat=None,\n",
    "                num_samples=100, return_samples=False, quantiles=[\"0.1\", \"0.5\", \"0.9\"]):\n",
    "        \"\"\"Requests the prediction of for the time series listed in `ts`, each with the (optional)\n",
    "        corresponding category listed in `cat`.\n",
    "\n",
    "        ts -- `pandas.Series` object, the time series to predict\n",
    "        cat -- integer, the group associated to the time series (default: None)\n",
    "        num_samples -- integer, number of samples to compute at prediction time (default: 100)\n",
    "        return_samples -- boolean indicating whether to include samples in the response (default: False)\n",
    "        quantiles -- list of strings specifying the quantiles to compute (default: [\"0.1\", \"0.5\", \"0.9\"])\n",
    "\n",
    "        Return value: list of `pandas.DataFrame` objects, each containing the predictions\n",
    "        \"\"\"\n",
    "        prediction_time = ts.index[-1] + 1\n",
    "        quantiles = [str(q) for q in quantiles]\n",
    "        req = self.__encode_request(ts, cat, dynamic_feat, num_samples, return_samples, quantiles)\n",
    "        res = super(DeepARPredictor, self).predict(req)\n",
    "        return self.__decode_response(res, ts.index.freq, prediction_time, return_samples)\n",
    "\n",
    "    def __encode_request(self, ts, cat, dynamic_feat, num_samples, return_samples, quantiles):\n",
    "        instance = series_to_dict(ts, cat if cat is not None else None, dynamic_feat if dynamic_feat else None)\n",
    "\n",
    "        configuration = {\n",
    "            \"num_samples\": num_samples,\n",
    "            \"output_types\": [\"quantiles\", \"samples\"] if return_samples else [\"quantiles\"],\n",
    "            \"quantiles\": quantiles\n",
    "        }\n",
    "\n",
    "        http_request_data = {\n",
    "            \"instances\": [instance],\n",
    "            \"configuration\": configuration\n",
    "        }\n",
    "\n",
    "        return json.dumps(http_request_data).encode('utf-8')\n",
    "\n",
    "    def __decode_response(self, response, freq, prediction_time, return_samples):\n",
    "        # we only sent one time series so we only receive one in return\n",
    "        # however, if possible one will pass multiple time series as predictions will then be faster\n",
    "        predictions = json.loads(response.decode('utf-8'))['predictions'][0]\n",
    "        prediction_length = len(next(iter(predictions['quantiles'].values())))\n",
    "        prediction_index = pd.DatetimeIndex(start=prediction_time, freq=freq, periods=prediction_length)\n",
    "        if return_samples:\n",
    "            dict_of_samples = {'sample_' + str(i): s for i, s in enumerate(predictions['samples'])}\n",
    "        else:\n",
    "            dict_of_samples = {}\n",
    "        return pd.DataFrame(data={**predictions['quantiles'], **dict_of_samples}, index=prediction_index)\n",
    "\n",
    "    def set_frequency(self, freq):\n",
    "        self.freq = freq\n",
    "\n",
    "def encode_target(ts):\n",
    "    return [x if np.isfinite(x) else \"NaN\" for x in ts]\n",
    "\n",
    "def series_to_dict(ts, cat=None, dynamic_feat=None):\n",
    "    \"\"\"Given a pandas.Series object, returns a dictionary encoding the time series.\n",
    "\n",
    "    ts -- a pands.Series object with the target time series\n",
    "    cat -- an integer indicating the time series category\n",
    "\n",
    "    Return value: a dictionary\n",
    "    \"\"\"\n",
    "    obj = {\"start\": str(ts.index[0]), \"target\": encode_target(ts)}\n",
    "    if cat is not None:\n",
    "        obj[\"cat\"] = cat\n",
    "    if dynamic_feat is not None:\n",
    "        obj[\"dynamic_feat\"] = dynamic_feat\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_endpoint_name = prefix + time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "\n",
    "xgb_predictor = xgb_estimator.deploy(\n",
    "                     initial_instance_count=1, \n",
    "                     instance_type='ml.m4.xlarge',\n",
    "                     predictor_cls=XGBoostPredictor,\n",
    "                     endpoint_name=xgb_endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, raw_outputs = model.predict([\"\"\"Very funny. A typical mid 50's comedy.\"\"\"])\n",
    "print('Predictions: {}'.format(predictions))\n",
    "print('Raw outputs: {}'.format(raw_outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, raw_outputs = bert_model.predict([\"\"\"That movie was absolutely awful.\"\"\"])\n",
    "print('Predictions: {}'.format(predictions))\n",
    "print('Raw outputs: {}'.format(raw_outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
