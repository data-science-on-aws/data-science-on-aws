{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "source ~/.bash_profile\n",
    "\n",
    "aws ecr create-repository --repository-name workshop\n",
    "\n",
    "#### Build and push a custom Docker container\n",
    "export ECR_REPOSITORY_URI=$(aws ecr describe-repositories --repository-names workshop --query \"repositories[].repositoryUri\" --output text)\n",
    "echo \"export ECR_REPOSITORY_URI=${ECR_REPOSITORY_URI}\" | tee -a ~/.bash_profile\n",
    "\n",
    "# Log in to the AWS Deep Learning registry.  We will extend the base Docker images in this repo.\n",
    "$(aws ecr get-login --no-include-email --region us-west-2 --registry-ids 763104351884)\n",
    "\n",
    "### EXPECTED OUTPUT ###\n",
    "# ...\n",
    "# Login Succeeded\n",
    "\n",
    "# In our Dockerfile we start with an AWS Deep Learning TensorFlow container and copy our training code into the container.\n",
    "\n",
    "cd docker/\n",
    "\n",
    "# cat Dockerfile\n",
    "\n",
    "### EXPECTED OUTPUT ###\n",
    "# FROM 763104351884.dkr.ecr.us-west-2.amazonaws.com/tensorflow-training:1.14.0-cpu-py36-ubuntu16.04\n",
    "# COPY code /opt/training/\n",
    "# WORKDIR /opt/training\n",
    "\n",
    "# Run `docker build` command\n",
    "docker build -t ${ECR_REPOSITORY_URI}:latest -f Dockerfile.cpu . # <== MAKE SURE YOU INCLUDE THE `.` AT THE END!\n",
    "\n",
    "# Log in to your docker registry\n",
    "$(aws ecr get-login --no-include-email --region us-west-2)\n",
    "\n",
    "### EXPECTED OUTPUT ###\n",
    "# ...\n",
    "# Login Succeeded\n",
    "\n",
    "# Push your image to ECR\n",
    "docker push ${ECR_REPOSITORY_URI}:latest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Create Docker Image for Distributed Training Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sed: can't read TODO.yaml: No such file or directory\n",
      "The connection to the server localhost:8080 was refused - did you specify the right host or port?\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "sed -i.bak -e \"s@YOUR_DOCKER_IMAGE@${ECR_REPOSITORY_URI}:latest@\" TODO.yaml\n",
    "\n",
    "#### Submit a job run:\n",
    "kubectl create -f TODO.yaml\n",
    "\n",
    "echo \"Completed\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Verify Job is Running\n",
    "\n",
    "_Note: You may see some pods in the Initializing state. This is OK. Try again in a few seconds._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "kubectl get pods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulations!\n",
    "\n",
    "You have just trained a Distributed TensorFlow Model on Amazon EKS with a distributed file system backed by S3!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
