{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Python packages in the current Jupyter Kernel\n",
    "\n",
    "If you're in the jupyter notebook and you want to install a package with `pip`, you might be tempted to use the `!` notation to run pip directly as a shell command from the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Develop your model and run inside notebook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import os\n",
    "import subprocess\n",
    "import argparse\n",
    "\n",
    "# Reduce spam logs from s3 client\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='3'\n",
    "\n",
    "def preprocessing():\n",
    "  fashion_mnist = keras.datasets.fashion_mnist\n",
    "  (train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "  # scale the values to 0.0 to 1.0\n",
    "  train_images = train_images / 255.0\n",
    "  test_images = test_images / 255.0\n",
    "\n",
    "  # reshape for feeding into the model\n",
    "  train_images = train_images.reshape(train_images.shape[0], 28, 28, 1)\n",
    "  test_images = test_images.reshape(test_images.shape[0], 28, 28, 1)\n",
    "\n",
    "  class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "                'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "  print('\\ntrain_images.shape: {}, of {}'.format(train_images.shape, train_images.dtype))\n",
    "  print('test_images.shape: {}, of {}'.format(test_images.shape, test_images.dtype))\n",
    "\n",
    "  return train_images, train_labels, test_images, test_labels\n",
    "\n",
    "def train(train_images, train_labels, epochs, model_summary_path):\n",
    "  if model_summary_path:\n",
    "    logdir=model_summary_path # + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "  model = keras.Sequential([\n",
    "    keras.layers.Conv2D(input_shape=(28,28,1), filters=8, kernel_size=3,\n",
    "                        strides=2, activation='relu', name='Conv1'),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax, name='Softmax')\n",
    "  ])\n",
    "  model.summary()\n",
    "\n",
    "  model.compile(optimizer=tf.train.AdamOptimizer(),\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy']\n",
    "                )\n",
    "  if model_summary_path:\n",
    "    model.fit(train_images, train_labels, epochs=epochs, callbacks=[tensorboard_callback])\n",
    "  else:\n",
    "    model.fit(train_images, train_labels, epochs=epochs)\n",
    "\n",
    "  return model\n",
    "\n",
    "def eval(model, test_images, test_labels):\n",
    "  test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "  print('\\nTest accuracy: {}'.format(test_acc))\n",
    "\n",
    "def export_model(model, model_export_path):\n",
    "  version = 1\n",
    "  export_path = os.path.join(model_export_path, str(version))\n",
    "\n",
    "  tf.saved_model.simple_save(\n",
    "    keras.backend.get_session(),\n",
    "    export_path,\n",
    "    inputs={'input_image': model.input},\n",
    "    outputs={t.name:t for t in model.outputs})\n",
    "\n",
    "  print('\\nSaved model: {}'.format(export_path))\n",
    "\n",
    "\n",
    "def main(argv=None):\n",
    "  parser = argparse.ArgumentParser(description='Fashion MNIST Tensorflow Example')\n",
    "  parser.add_argument('--model_export_path', type=str, help='Model export path')\n",
    "  parser.add_argument('--model_summary_path', type=str,  help='Model summry files for Tensorboard visualization')\n",
    "  parser.add_argument('--epochs', type=int, default=5, help='Training epochs')\n",
    "  args = parser.parse_args(args=[])\n",
    "\n",
    "  train_images, train_labels, test_images, test_labels = preprocessing()\n",
    "  model = train(train_images, train_labels, args.epochs, args.model_summary_path)\n",
    "  eval(model, test_images, test_labels)\n",
    "\n",
    "  if args.model_export_path:\n",
    "    export_model(model, args.model_export_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sharing your notebooks\n",
    "\n",
    "When we talk of sharing their notebooks, there are generally two paradigms they may be considering. Most often, individuals share the end-result of their work, which means sharing non-interactive, pre-rendered versions of their notebooks; however, it is also possible to collaborate on notebooks with the aid version control systems such as Git.\n",
    "\n",
    "### Before your share\n",
    "A shared notebook will appear exactly in the state it was in when you export or save it, including the output of any code cells. Therefore, to ensure that your notebook is share-ready, so to speak, there are a few steps you should take before sharing:\n",
    "\n",
    "- Click \"Cell > All Output > Clear\"\n",
    "- Click \"Kernel > Restart & Run All\"\n",
    "- Wait for your code cells to finish executing and check they did so as expected\n",
    "\n",
    "This will ensure your notebooks donâ€™t contain intermediary output, have a stale state, and executed in order at the time of sharing.\n",
    "\n",
    "- Click \"Cell > All Output > Clear\" (One more time to clearn up results)\n",
    "- Click \"File > Download as > Notebook\" and export your notebook\n",
    "\n",
    "\n",
    "### Workspace Volume\n",
    "By default, when you delete your notebook, workspace volume will not be deleted.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
